{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe344b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########Import Dependencies##############\n",
    "from config import db_password\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013f05a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Import the JSON Wikipedia File #############\n",
    "file_dir = 'C:/users/sljss/Desktop/movies-etl/'\n",
    "file_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c9ed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f'{file_dir}wikipedia-movies.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c288ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a function to read in the  file and give it a name \n",
    "with open ('wikipedia-movies.json', mode='r') as file:\n",
    "    wiki_movies_raw = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a266726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wiki_movies_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c997c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 5 records\n",
    "wiki_movies_raw[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe89107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last 5 records\n",
    "wiki_movies_raw[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2267093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some records in the middle\n",
    "wiki_movies_raw[3600:3605]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75498e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read CSV files\n",
    "kaggle_metadata = pd.read_csv(f'{file_dir}movies_metadata.csv', low_memory=False)\n",
    "ratings = pd.read_csv(f'{file_dir}ratings.csv')\n",
    "# ratings.head(5)\n",
    "# ratings.tail(5)\n",
    "# kaggle_metadata.head(5)\n",
    "# kaggle_metadata.tail(5)\n",
    "# ratings.sample()\n",
    "# ratings.sample(5)\n",
    "# kaggle_metadata.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137272e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Turn the wiki_movies_raw dictonary into a Dataframe\n",
    "wiki_movies_df = pd.DataFrame(wiki_movies_raw)\n",
    "wiki_movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d14f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Lots of Columns Cant see them all, convert the df columns to a list  #########\n",
    "wiki_movies_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031885d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Use List Comprehension to filter the data - Save to an intermediate variable (wiki_movies) #############\n",
    "wiki_movies = [movie for movie in wiki_movies_raw\n",
    "               if ('Director' in movie or 'Directed by' in movie)\n",
    "                   and 'imdb_link' in movie]\n",
    "len(wiki_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6942480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "####  Add the new list to a dataframe went from 193 columns to 78 #######\n",
    "wiki_movies_df = pd.DataFrame(wiki_movies)\n",
    "wiki_movies_df.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857d1b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Filter out the no of episodes, they dont belong, using movies only #####\n",
    "wiki_movies = [movie for movie in wiki_movies_raw\n",
    "               if ('Director' in movie or 'Directed by' in movie)\n",
    "                   and 'imdb_link' in movie\n",
    "                   and 'No. of episodes' not in movie]\n",
    "len(wiki_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1a3e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Make a Function that performs the cleaning process ########\n",
    "##### Four Basic Parts: Name, Parameters, Code Block, Return Value #############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7ed15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Write a simple function to make a copy of the movie and return it (preserved the original copy in case you mess up)\n",
    "def clean_movie(movie):\n",
    "    movie = dict(movie) #create a non-destructive copy\n",
    "    \n",
    "    return movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9f3d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Take  a look at the Languages #####\n",
    "wiki_movies_df[wiki_movies_df['Arabic'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7465aa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movies_df[wiki_movies_df['Arabic'].notnull()]['url']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35664f4",
   "metadata": {},
   "source": [
    "# STEP ONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2306f768",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Make an Empty Dict to hold all of the alternative titles  Add to the function previously created #########\n",
    "# def clean_movie(movie):\n",
    "#     movie = dict(movie) #create a non-destructive copy\n",
    "#     alt_titles = {}\n",
    "#     return movie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51286879",
   "metadata": {},
   "source": [
    "# STEP TWO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f5e45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Loop through a list of all alternative title keys\n",
    "# def clean_movie(movie):\n",
    "#     movie = dict(movie) #create a non-destructive copy\n",
    "#     alt_titles = {}\n",
    "#     for key in ['Also known as','Arabic','Cantonese','Chinese','French',\n",
    "#                 'Hangul','Hebrew','Hepburn','Japanese','Literally',\n",
    "#                 'Mandarin','McCune–Reischauer','Original title','Polish',\n",
    "#                 'Revised Romanization','Romanized','Russian',\n",
    "#                 'Simplified','Traditional','Yiddish']:\n",
    "\n",
    "#     return movie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee6cd85",
   "metadata": {},
   "source": [
    "# STEP 2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6d3562",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Check if the current key exists in the movie object\n",
    "# def clean_movie(movie):\n",
    "#     movie = dict(movie) #create a non-destructive copy\n",
    "#     alt_titles = {}\n",
    "#     for key in ['Also known as','Arabic','Cantonese','Chinese','French',\n",
    "#                 'Hangul','Hebrew','Hepburn','Japanese','Literally',\n",
    "#                 'Mandarin','McCune–Reischauer','Original title','Polish',\n",
    "#                 'Revised Romanization','Romanized','Russian',\n",
    "#                 'Simplified','Traditional','Yiddish']:\n",
    "#         if key in movie:\n",
    "\n",
    "#     return movie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0a4816",
   "metadata": {},
   "source": [
    "# STEP 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e5ff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### If so, remove the key-value pairs and add to the alternative titles dictionary\n",
    "##### Hint: To remove a key-value pair from a dict in Python, use the pop() method.\n",
    "# def clean_movie(movie):\n",
    "#     movie = dict(movie) #create a non-destructive copy\n",
    "#     alt_titles = {}\n",
    "#     for key in ['Also known as','Arabic','Cantonese','Chinese','French',\n",
    "#                 'Hangul','Hebrew','Hepburn','Japanese','Literally',\n",
    "#                 'Mandarin','McCune–Reischauer','Original title','Polish',\n",
    "#                 'Revised Romanization','Romanized','Russian',\n",
    "#                 'Simplified','Traditional','Yiddish']:\n",
    "#         if key in movie:\n",
    "#             alt_titles[key] = movie[key]\n",
    "#             movie.pop(key)\n",
    "\n",
    "\n",
    "#     return movie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3608ad",
   "metadata": {},
   "source": [
    "# STEP 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135484f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "####  After looping through every key, add the alternative titles dict to the movie object\n",
    "def clean_movie(movie):\n",
    "    movie = dict(movie) #create a non-destructive copy\n",
    "    alt_titles = {}\n",
    "    for key in ['Also known as','Arabic','Cantonese','Chinese','French',\n",
    "                'Hangul','Hebrew','Hepburn','Japanese','Literally',\n",
    "                'Mandarin','McCune–Reischauer','Original title','Polish',\n",
    "                'Revised Romanization','Romanized','Russian',\n",
    "                'Simplified','Traditional','Yiddish']:\n",
    "        if key in movie:\n",
    "            alt_titles[key] = movie[key]\n",
    "            movie.pop(key)\n",
    "    if len(alt_titles) > 0:\n",
    "        movie['alt_titles'] = alt_titles\n",
    "\n",
    "    return movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d08851",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Make a list of cleaned movies with list comprehension\n",
    "clean_movies = [clean_movie(movie) for movie in wiki_movies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01cac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Set wiki_movies_df to be the datafreame created from clean_movies and print out columns\n",
    "wiki_movies_df = pd.DataFrame(clean_movies)\n",
    "sorted(wiki_movies_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1b6cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_movie(movie):\n",
    "    movie = dict(movie) #create a non-destructive copy\n",
    "    alt_titles = {}\n",
    "     # combine alternate titles into one list\n",
    "    for key in ['Also known as','Arabic','Cantonese','Chinese','French',\n",
    "                'Hangul','Hebrew','Hepburn','Japanese','Literally',\n",
    "                'Mandarin','McCune–Reischauer','Original title','Polish',\n",
    "                'Revised Romanization','Romanized','Russian',\n",
    "                'Simplified','Traditional','Yiddish']:\n",
    "        if key in movie:\n",
    "            alt_titles[key] = movie[key]\n",
    "            movie.pop(key)\n",
    "    if len(alt_titles) > 0:\n",
    "        movie['alt_titles'] = alt_titles\n",
    "        \n",
    "    # merge column names\n",
    "    def change_column_name(old_name, new_name):\n",
    "        if old_name in movie:\n",
    "            movie[new_name] = movie.pop(old_name)\n",
    "                \n",
    "    change_column_name('Adaptation by', 'Writer(s)')\n",
    "    change_column_name('Country of origin', 'Country')\n",
    "    change_column_name('Directed by', 'Director')\n",
    "    change_column_name('Distributed by', 'Distributor')\n",
    "    change_column_name('Edited by', 'Editor(s)')\n",
    "    change_column_name('Length', 'Running time')\n",
    "    change_column_name('Original release', 'Release date')\n",
    "    change_column_name('Music by', 'Composer(s)')\n",
    "    change_column_name('Produced by', 'Producer(s)')\n",
    "    change_column_name('Producer', 'Producer(s)')\n",
    "    change_column_name('Productioncompanies ', 'Production company(s)')\n",
    "    change_column_name('Productioncompany ', 'Production company(s)')\n",
    "    change_column_name('Released', 'Release Date')\n",
    "    change_column_name('Release Date', 'Release date')\n",
    "    change_column_name('Screen story by', 'Writer(s)')\n",
    "    change_column_name('Screenplay by', 'Writer(s)')\n",
    "    change_column_name('Story by', 'Writer(s)')\n",
    "    change_column_name('Theme music composer', 'Composer(s)')\n",
    "    change_column_name('Written by', 'Writer(s)')\n",
    "\n",
    "    return movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba179f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Rerun our list comprehension to clean wiki_movies and recreate wiki_movies_df\n",
    "clean_movies = [clean_movie(movie) for movie in wiki_movies]\n",
    "wiki_movies_df = pd.DataFrame(clean_movies)\n",
    "sorted(wiki_movies_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74071aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Remove Duplicate Rows (First extract the IMDb ID from the IMDb link)##############\n",
    "## str.extract()\n",
    "## \"(tt\\d{7})\"\n",
    "# \"(tt\\d{7})\" — The parentheses marks say to look for one group of text.\n",
    "# \"(tt\\d{7})\" — The \"tt\" in the string simply says to match two lowercase Ts.\n",
    "# \"(tt\\d{7})\" — The \"\\d\" says to match a numerical digit.\n",
    "# \"(tt\\d{7})\" — The \"{7}\" says to match the last thing (numerical digits) exactly seven times.\n",
    "# drop_duplicates()\n",
    "# use the subset argument and set inplace=True so that the operation is performed ont he selected dataframe\n",
    "wiki_movies_df['imdb_id'] = wiki_movies_df['imdb_link'].str.extract(r'(tt\\d{7})')\n",
    "print(len(wiki_movies_df))\n",
    "wiki_movies_df.drop_duplicates(subset='imdb_id', inplace=True)\n",
    "print(len(wiki_movies_df))\n",
    "wiki_movies_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9344a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check for null values in the columns\n",
    "### List Comprehension method\n",
    "[[column,wiki_movies_df[column].isnull().sum()] for column in wiki_movies_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8837a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make a list of columns that hve less than 90% null values and use those to trim down our dataset\n",
    "## Tweak our list comprehension code from \n",
    "##### [[column,wiki_movies_df[column].isnull().sum()] for column in wiki_movies_df.columns]\n",
    "##### to [column for column in wiki_movies_df.columns if wiki_movies_df[column].isnull().sum() < len(wiki_movies_df) * 0.9]\n",
    "\n",
    "wiki_columns_to_keep = [column for column in wiki_movies_df.columns if wiki_movies_df[column].isnull().sum() < len(wiki_movies_df) * 0.9]\n",
    "wiki_movies_df = wiki_movies_df[wiki_columns_to_keep]\n",
    "wiki_movies_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6c9968",
   "metadata": {},
   "source": [
    "# USE REGULAR EXPRESSIONS TO ENSURE YOU HAVE THE RIGHT DATATYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16d38fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Identify which columns need to be converted using df.dtypes\n",
    "# Box office should be numeric.\n",
    "# Budget should be numeric.\n",
    "# Release date should be a date object.\n",
    "# Running time should be numeric.\n",
    "wiki_movies_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9f5a55",
   "metadata": {},
   "source": [
    "# Box Office Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0256c078",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fix the box office data (which should be numeric) to use for budget data since they are both numeric\n",
    "### Drop the missing values using .dropna()\n",
    "box_office = wiki_movies_df['Box office'].dropna()\n",
    "### Check the values after dropna()  Evaluate the change from 7033 tp 5485\n",
    "box_office\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945dd804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Regular expressons work on only strings, make sure all the box office data is entered as a string. \n",
    "### Use the map() method we can see which values are not strings\n",
    "### make is_not_a_string() a function\n",
    "def is_not_a_string(x):\n",
    "    return type(x) !=str\n",
    "box_office[box_office.map(is_not_a_string)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e635ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Update our map() function to a lambda expression\n",
    "box_office[box_office.map(lambda x: type(x) != str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12601242",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Concatenate list items into one string\n",
    "## make a separator string then call the join() method\n",
    "### For example\n",
    "some_list = ['One','Two','Three']\n",
    "'Mississippi'.join(some_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60db0508",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use a simple space as a separator string then call the join() method\n",
    "box_office = box_office.apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "box_office"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c57a8c",
   "metadata": {},
   "source": [
    "# Parse the box office Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff21abbd",
   "metadata": {},
   "source": [
    "## Create the first form - 6 elements\n",
    "\n",
    "### 1. A dollar sign\n",
    "### 2. An arbitrary (but non-zero) number of digits\n",
    "### 3. An optional decimal point\n",
    "### 4. An arbitrary (but possibly zero) number of more digits\n",
    "### 5. A space (maybe more than one)\n",
    "### 6. The word \"million\" or \"billion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0818a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Start with a dollar sign. Escape the dollar sign - '\\$'\n",
    "\n",
    "# Step 2: Add an arbitrary (but non-zero) number of digits. \n",
    "# Add the '\\d' character to specify digits only and the '+' modifier to capture one or more digits - '\\$\\d+'\n",
    "\n",
    "# Step 3: Add an optional decimal point. (Since its optional include the ?) - '\\$\\d+\\.?'\n",
    "\n",
    "# Step 4: Add an arbitrary (but possibly zero) number of more digits.\n",
    "# Use the \\d character to sepcify digits only, add a * modifier becasue there many be no digits after the decimal '\\$\\d+\\.?\\d*'\n",
    "\n",
    "# Step 5: Add a space (maybe more than one).\n",
    "# use \\s to match whitespace, to be safe match any number of whitespace characters with * '\\$\\d+\\.?\\d*\\s*'\n",
    "\n",
    "# Step 6: Add the word \"million\" or \"billion.\" Use Character set add [mb]illion - '\\$\\d+\\.?\\d*\\s*[mb]illion'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ff0cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a variable (form_one) and set it equal to the finished regular expression string with an 'r'\n",
    "form_one = r'\\$\\d+\\.?\\d*\\s*[mb]illion'\n",
    "\n",
    "## Count up how many box office values match our first form - use str.contains() on box_office\n",
    "## To ignore whether letters are uppercase of lowercase add an argument called flags and set it equal to re.IGNORECASE\n",
    "## In case the data is not a string, add the na=False argument to parse the non-string stat to false\n",
    "## Call the sum() method to count up the total number that return True\n",
    "\n",
    "box_office.str.contains(form_one, flags=re.IGNORECASE, na=False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c241435",
   "metadata": {},
   "source": [
    "## Create the Second Form 3 Elements\n",
    "\n",
    "### 1. A dollar sign\n",
    "### 2. A group of one to three digits\n",
    "### 3. At least one group starting with a comma and followed by exactly three digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4122ce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Start with a dollar sign. Escape the dollar sign \\$\n",
    "\n",
    "# Step 2: Add a group of one to three digits. use \\d with curly brackets to only match 1 through 3 repetitions '\\$\\d{1,3}'\n",
    "\n",
    "# Step 3: Match at least one group starting with a comma and followed by exactly three digits. ',\\d{3}'\n",
    "# To match any repetition of that group, we'll put it inside parenthesis and add a '+' sign after the parenthesis '(,\\d{3})+'\n",
    "# Specify that this is a non capturing group by inserting a ? and : after the opening parenthesis '(?:,\\d{3})+' (Not necessary)\n",
    "#  Finished regular expression string '\\$\\d{1,3}(?:,\\d{3})+'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f41061",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a variable (form_two) and set it equal to the finished regular expression string with an 'r'\n",
    "form_two = r'\\$\\d{1,3}(?:,\\d{3})+'\n",
    "\n",
    "### Count up the number of box office values that match this pattern\n",
    "box_office.str.contains(form_two, flags=re.IGNORECASE, na=False).sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7049a59d",
   "metadata": {},
   "source": [
    "#  Compare Values in Forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a51a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### See which values are not described by either form, to be safe check is any values are described by both\n",
    "\n",
    "# Create 2 boolean series called matches_form_one and matches_form_two\n",
    "matches_form_one = box_office.str.contains(form_one, flags=re.IGNORECASE, na=False)\n",
    "matches_form_two = box_office.str.contains(form_two, flags=re.IGNORECASE, na=False)\n",
    "\n",
    "# See which values in box_office don't match either form\n",
    "# this will throw an error!  box_office[(not matches_form_one) and (not matches_form_two)]\n",
    "\n",
    "# Instead, Pandas has element-wise logical operators:\n",
    "# The element-wise negation operator is the tilde: ~ (similar to \"not\")\n",
    "# The element-wise logical \"and\" is the ampersand: &\n",
    "# The element-wise logical \"or\" is the pipe: |\n",
    "\n",
    "\n",
    "# What we want to use\n",
    "box_office[~matches_form_one & ~matches_form_two]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60242e6",
   "metadata": {},
   "source": [
    "# Fix Pattern Matches\n",
    "\n",
    "### Some values have spaces in between the dollar sign and the number.\n",
    "### Some values use a period as a thousands separator, not a comma.\n",
    "### Some values are given as a range.\n",
    "### \"Million\" is sometimes misspelled as \"millon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dbe9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Some values have spaces in between the dollar sign and the number.add \\s* after the dollar signs\n",
    "#  New forms should like the following below\n",
    "# form_one = r'\\$\\s*\\d+\\.?\\d*\\s*[mb]illion'\n",
    "# form_two = r'\\$\\s*\\d{1,3}(?:,\\d{3})+'\n",
    "\n",
    "## 2. Some values use a period as a thousands separator, not a comma.\n",
    "# Change form_two to allow for either a comma or a period as a thousands separator\n",
    "# form_two = r'\\$\\s*\\d{1,3}(?:,\\d{3})+'   changes to  r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+'\n",
    "# Add a negative lookahead group that looks ahead for million of billion after the number and rejects the match if found \n",
    "#  Dont forget the space!!!\n",
    "# form_two = r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)'\n",
    "\n",
    "## 3. Some values are given as a range.\n",
    "# Search for any string that starts with a $ and ends with a -, then replace it with a $ using replace()\n",
    "# The 1st argument in the replace() method is the substring that will be replaced\n",
    "# The 2nd argument in the replace() method is the string to replace it with\n",
    "# We can use regular expressions in the 1st argument by sending the parameter 'regex=True'\n",
    "# box_office = box_office.str.replace(r'\\$.*[-—–](?![a-z])', '$', regex=True)\n",
    "\n",
    "## 4. \"Million\" is sometimes misspelled as \"millon.\"\n",
    "##  Make the 2nd i optional in our match string with a question mark\n",
    "# form_one = r'\\$\\s*\\d+\\.?\\d*\\s*[mb]illi?on'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a25c69",
   "metadata": {},
   "source": [
    "# Extract and Convert the Box Office Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed52edae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a regular expression that matches either form_one or form_two (use an f string) :| means 'OR'\n",
    "box_office.str.extract(f'({form_one}|{form_two})')\n",
    "\n",
    "## Make a function to turn the extracted values into a numeric value. Call it parse_dollars \n",
    "## parse_dollars will take in a dtring and return a floating decimal point number.\n",
    "###########################################################################################################\n",
    "## Skeleton Function\n",
    "###########################################################################################################\n",
    "# def parse_dollars(s):\n",
    "    # if s is not a string, return NaN\n",
    "\n",
    "    # if input is of the form $###.# million\n",
    "\n",
    "        # remove dollar sign and \" million\"\n",
    "\n",
    "        # convert to float and multiply by a million\n",
    "\n",
    "        # return value\n",
    "\n",
    "    # if input is of the form $###.# billion\n",
    "\n",
    "        # remove dollar sign and \" billion\"\n",
    "\n",
    "        # convert to float and multiply by a billion\n",
    "\n",
    "        # return value\n",
    "\n",
    "    # if input is of the form $###,###,###\n",
    "\n",
    "        # remove dollar sign and commas\n",
    "\n",
    "        # convert to float\n",
    "\n",
    "        # return value\n",
    "\n",
    "    # otherwise, return NaN\n",
    "###########################################################################################################\n",
    "##  Use the re module to access the regular expression functions. \n",
    "## Use re.match(pattern, string) to see if our string matches a pattern    \n",
    "# Split the million and billion matches from form_one\n",
    "###########################################################################################################\n",
    "# def parse_dollars(s):\n",
    "#     # if s is not a string, return NaN\n",
    "#     if type(s) != str:\n",
    "#         return np.nan\n",
    "\n",
    "#     # if input is of the form $###.# million\n",
    "#     if re.match(r'\\$\\s*\\d+\\.?\\d*\\s*milli?on', s, flags=re.IGNORECASE):\n",
    "\n",
    "#         # remove dollar sign and \" million\"\n",
    "\n",
    "#         # convert to float and multiply by a million\n",
    "\n",
    "#         # return value\n",
    "\n",
    "#     # if input is of the form $###.# billion\n",
    "#     elif re.match(r'\\$\\s*\\d+\\.?\\d*\\s*billi?on', s, flags=re.IGNORECASE):\n",
    "\n",
    "#         # remove dollar sign and \" billion\"\n",
    "\n",
    "#         # convert to float and multiply by a billion\n",
    "\n",
    "#         # return value\n",
    "\n",
    "#     # if input is of the form $###,###,###\n",
    "#     elif re.match(r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)', s, flags=re.IGNORECASE):\n",
    "\n",
    "#         # remove dollar sign and commas\n",
    "\n",
    "#         # convert to float\n",
    "\n",
    "#         # return value\n",
    "\n",
    "#     # otherwise, return NaN\n",
    "#     else:\n",
    "#         return np.nan\n",
    "###########################################################################################################\n",
    "###  Use re.sub(pattern, replacement_string, string) to remove dollar signs, spaces, commas, and letters\n",
    "###########################################################################################################\n",
    "# def parse_dollars(s):\n",
    "#     # if s is not a string, return NaN\n",
    "#     if type(s) != str:\n",
    "#         return np.nan\n",
    "\n",
    "#     # if input is of the form $###.# million\n",
    "#     if re.match(r'\\$\\s*\\d+\\.?\\d*\\s*milli?on', s, flags=re.IGNORECASE):\n",
    "\n",
    "#         # remove dollar sign and \" million\"\n",
    "#         s = re.sub('\\$|\\s|[a-zA-Z]','', s)\n",
    "\n",
    "#         # convert to float and multiply by a million\n",
    "\n",
    "#         # return value\n",
    "\n",
    "#     # if input is of the form $###.# billion\n",
    "#     elif re.match(r'\\$\\s*\\d+\\.?\\d*\\s*billi?on', s, flags=re.IGNORECASE):\n",
    "\n",
    "#         # remove dollar sign and \" billion\"\n",
    "#         s = re.sub('\\$|\\s|[a-zA-Z]','', s)\n",
    "\n",
    "#         # convert to float and multiply by a billion\n",
    "\n",
    "#         # return value\n",
    "\n",
    "#     # if input is of the form $###,###,###\n",
    "#     elif re.match(r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)', s, flags=re.IGNORECASE):\n",
    "\n",
    "#         # remove dollar sign and commas\n",
    "#         s = re.sub('\\$|,','', s)\n",
    "\n",
    "#         # convert to float\n",
    "\n",
    "#         # return value\n",
    "\n",
    "#     # otherwise, return NaN\n",
    "#     else:\n",
    "#         return np.nan\n",
    "###########################################################################################################\n",
    "## Conver all the strings to floats, multiply by the right amount and return the value\n",
    "###########################################################################################################\n",
    "def parse_dollars(s):\n",
    "    # if s is not a string, return NaN\n",
    "    if type(s) != str:\n",
    "        return np.nan\n",
    "\n",
    "    # if input is of the form $###.# million\n",
    "    if re.match(r'\\$\\s*\\d+\\.?\\d*\\s*milli?on', s, flags=re.IGNORECASE):\n",
    "\n",
    "        # remove dollar sign and \" million\"\n",
    "        s = re.sub('\\$|\\s|[a-zA-Z]','', s)\n",
    "\n",
    "        # convert to float and multiply by a million\n",
    "        value = float(s) * 10**6\n",
    "\n",
    "        # return value\n",
    "        return value\n",
    "\n",
    "    # if input is of the form $###.# billion\n",
    "    elif re.match(r'\\$\\s*\\d+\\.?\\d*\\s*billi?on', s, flags=re.IGNORECASE):\n",
    "\n",
    "        # remove dollar sign and \" billion\"\n",
    "        s = re.sub('\\$|\\s|[a-zA-Z]','', s)\n",
    "\n",
    "        # convert to float and multiply by a billion\n",
    "        value = float(s) * 10**9\n",
    "\n",
    "        # return value\n",
    "        return value\n",
    "\n",
    "    # if input is of the form $###,###,###\n",
    "    elif re.match(r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)', s, flags=re.IGNORECASE):\n",
    "\n",
    "        # remove dollar sign and commas\n",
    "        s = re.sub('\\$|,','', s)\n",
    "\n",
    "        # convert to float\n",
    "        value = float(s)\n",
    "\n",
    "        # return value\n",
    "        return value\n",
    "\n",
    "    # otherwise, return NaN\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d715d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract the values form box_office using str.extract\n",
    "## Apply parse_dollars to find the 1st column in the dataframe returned by str.exract\n",
    "wiki_movies_df['box_office'] = box_office.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\n",
    "wiki_movies_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bb3bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397ecf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  We no longer need the box office column, so drop it\n",
    "wiki_movies_df.drop('Box office', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5043505c",
   "metadata": {},
   "source": [
    "## Parse Budget Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e029b706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a budget variable\n",
    "budget = wiki_movies_df['Budget'].dropna()\n",
    "\n",
    "# Convert any lists to strings\n",
    "budget = budget.map(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "\n",
    "# Remove any values between a dollar sign and a hyphen (for budgets in given ranges)\n",
    "budget = budget.str.replace(r'\\$.*[-—–](?![a-z])', '$', regex=True)\n",
    "\n",
    "# Parse the data like you did for box_office data\n",
    "matches_form_one = budget.str.contains(form_one, flags=re.IGNORECASE, na=False)\n",
    "matches_form_two = budget.str.contains(form_two, flags=re.IGNORECASE, na=False)\n",
    "budget[~matches_form_one & ~matches_form_two]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368333f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Citations references are in the data (numbers in square brackets []) remove with a regular expression '\\[\\d+\\]'\n",
    "## Remove the citation references \n",
    "budget = budget.str.replace(r'\\[\\d+\\]\\s*', '')\n",
    "budget[~matches_form_one & ~matches_form_two]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a43a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pase the budget values - Copy the code we used to part the box office values changing box_office to budget\n",
    "wiki_movies_df['budget'] = budget.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\n",
    "## Drop the original budget column\n",
    "wiki_movies_df.drop('Budget', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd71fa72",
   "metadata": {},
   "source": [
    "# Parse the Release Date \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad38dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Make a variable that holds the non-null values of Release date in teh Dataframe, converting lists to strings\n",
    "release_date = wiki_movies_df['Release date'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea9abfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  The forms we will parse (4)\n",
    "# Full month name, one- to two-digit day, four-digit year (i.e., January 1, 2000)\n",
    "# Four-digit year, two-digit month, two-digit day, with any separator (i.e., 2000-01-01)\n",
    "# Full month name, four-digit year (i.e., January 2000)\n",
    "# Four-digit year = r'\\d{4}'\n",
    "\n",
    "date_form_one = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s[123]?\\d,\\s\\d{4}'\n",
    "date_form_two = r'\\d{4}.[01]\\d.[0123]\\d'\n",
    "date_form_three = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s\\d{4}'\n",
    "date_form_four = r'\\d{4}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06929fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract the dates\n",
    "release_date.str.extract(f'({date_form_one}|{date_form_two}|{date_form_three}|{date_form_four})', flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c57226",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use the built-in to_datetime() methods in Panda to parse the dates\n",
    "## Since there are different date formats, set the infer_datetime_format option to True\n",
    "wiki_movies_df['release_date'] = pd.to_datetime(release_date.str.extract(f'({date_form_one}|{date_form_two}|{date_form_three}|{date_form_four})')[0], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2071fed9",
   "metadata": {},
   "source": [
    "# Parse Running Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e050dafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a variable that holds the non-null values of Release Date in the Dataframe, converting the lists to strings\n",
    "running_time = wiki_movies_df['Running time'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "running_time.head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33f9b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Use String boundaries to find how many entries just look like 11 minutes\n",
    "running_time.str.contains(r'^\\d*\\s*minutes$', flags=re.IGNORECASE, na=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8a4c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  What does the missing 366 entries look like\n",
    "running_time[running_time.str.contains(r'^\\d*\\s*minutes$', flags=re.IGNORECASE, na=False) != True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadf15a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make more general (drill down to abbreviations) Check list and ones left off\n",
    "# only mark the beginning of the string and accepting abbreviations of minutes by only searching up to the letter m\n",
    "running_time.str.contains(r'^\\d*\\s*m', flags=re.IGNORECASE, na=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a723e5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  The Ones left off\n",
    "running_time[running_time.str.contains(r'^\\d*\\s*m', flags=re.IGNORECASE, na=False) != True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b30185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## New regular expressions that relaces the condition of patterns starting at the beginning of the string (remove the ^)\n",
    "running_time.str.contains(r'\\d*\\s*m', flags=re.IGNORECASE, na=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a5831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Whats left behind\n",
    "running_time[running_time.str.contains(r'\\d*\\s*m', flags=re.IGNORECASE, na=False) != True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9132148",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  MAtch all of the hour + minute patterns with one regular expression pattern\n",
    "# Start with one or more digits.\n",
    "# Have an optional space after the digit and before the letter \"h.\"\n",
    "# Capture all the possible abbreviations of \"hour(s).\" To do this, we'll make every letter in \"hours\" optional except the \"h.\"\n",
    "# Have an optional space after the \"hours\" marker.\n",
    "# Have an optional number of digits for minutes.\n",
    "# Pattern = '\\d+\\s*ho?u?r?s?\\s*\\d*'\n",
    "\n",
    "## Extract values - we only want digits\n",
    "#  Add capture groups around the \\d instances as well as add an alternating character\n",
    "running_time_extract = running_time.str.extract(r'(\\d+)\\s*ho?u?r?s?\\s*(\\d*)|(\\d+)\\s*m')\n",
    "\n",
    "# The new FD is all strings, convert them to numeric values using to_numeric() and set the erros argument to coerce\n",
    "#  Coercing the errors will turn the empty strings into NAN, then we use fillna() to change them all to zeros\n",
    "running_time_extract = running_time_extract.apply(lambda col: pd.to_numeric(col, errors='coerce')).fillna(0)\n",
    "\n",
    "## Apply a function that converts the hour capture groups and minute capture groups to minutes if the pure minutes capture group is zero \n",
    "#  Save the output to wiki_movies_df\n",
    "wiki_movies_df['running_time'] = running_time_extract.apply(lambda row: row[0]*60 + row[1] if row[2] == 0 else row[2], axis=1)\n",
    "\n",
    "##  Drop Running Time from the dataset\n",
    "wiki_movies_df.drop('Running time', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aa5f01",
   "metadata": {},
   "source": [
    "# Clean the Kaggle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fb99b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initial look at Movie Metadata\n",
    "kaggle_metadata.dtypes\n",
    "\n",
    "# Need the convert these groups\n",
    "# popularity - numeric\n",
    "# adult - Boolean\n",
    "# Budget - numeric\n",
    "# release_date - datetime\n",
    "# video - Boolean\n",
    "# ID - numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ac7fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check for T of F for boolean datatypes (adult) and video using value_counts()\n",
    "kaggle_metadata['adult'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982b2af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove the Bad data\n",
    "kaggle_metadata[~kaggle_metadata['adult'].isin(['True','False'])]\n",
    "\n",
    "##  The data is too far gone, nothing with imdb_id just going to drop the data\n",
    "## In fact we dont want adult movies we will keep only rows where adult is False then dop the adult column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b1e2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Keeps the rows where the adult column is false and drops the adult column\n",
    "kaggle_metadata = kaggle_metadata[kaggle_metadata['adult'] == 'False'].drop('adult',axis='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7e0f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Look at the values of the video column\n",
    "kaggle_metadata['video'].value_counts()\n",
    "\n",
    "## Should only show true and false values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33015259",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert the video\n",
    "kaggle_metadata['video'] == 'True'\n",
    "## Assign it back to video\n",
    "kaggle_metadata['video'] = kaggle_metadata['video'] == 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822ebb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert the budget, id, and popularity to numeric using to_numeric()\n",
    "## Make sure the errors= argument is set to 'raise' to know if theres any data that cant be converted to numbers\n",
    "kaggle_metadata['budget'] = kaggle_metadata['budget'].astype(int)\n",
    "kaggle_metadata['id'] = pd.to_numeric(kaggle_metadata['id'], errors='raise')\n",
    "kaggle_metadata['popularity'] = pd.to_numeric(kaggle_metadata['popularity'], errors='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e4f75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert the release_date to datetime using Pandas to_datetime()\n",
    "## Since release_date is in a standard format, to_datetime should convert easily\n",
    "kaggle_metadata['release_date'] = pd.to_datetime(kaggle_metadata['release_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf500047",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Look at the Ratings Data\n",
    "## Use the info() method on the DF \n",
    "## Since the dataset has so many rows, we need to set the null_counts() option to True\n",
    "ratings.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3a967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  We wont be using the timestamp column\n",
    "## We will be storing the rating data as its own table in SQL\n",
    "## We will need to conver it to a datetime data type (# of seconds since midnight of January 1, 1970)\n",
    "## Speciy in to_datetime() that the origin is unix and the time unit is seconds\n",
    "pd.to_datetime(ratings['timestamp'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84c0d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assign it to the timestamp column\n",
    "ratings['timestamp'] = pd.to_datetime(ratings['timestamp'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95db69d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Look at the actual statistics of the actual ratings and see if there are errors (use describe() method) and a histogram\n",
    "pd.options.display.float_format = '{:20,.2f}'.format\n",
    "ratings['rating'].plot(kind='hist')\n",
    "ratings['rating'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff2e442",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Merge by IMDB ID then check for redundant columns\n",
    "##  Print out the list of columns = use the suffixes parameter to make it easier to identify which table each column came from\n",
    "movies_df = pd.merge(wiki_movies_df, kaggle_metadata, on='imdb_id', suffixes=['_wiki','_kaggle'])\n",
    "sorted(movies_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0730737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Look at Competing Data and drop redundant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948e8eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Competing data:\n",
    "# Wiki                     Movielens                Resolution\n",
    "#--------------------------------------------------------------------------\n",
    "# title_wiki               title_kaggle\n",
    "# running_time             runtime\n",
    "# budget_wiki              budget_kaggle\n",
    "# box_office               revenue\n",
    "# release_date_wiki        release_date_kaggle\n",
    "# Language                 original_language\n",
    "# Production company(s)    production_companies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76758c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compare the data between the titles\n",
    "movies_df[['title_wiki','title_kaggle']]\n",
    "## Pretty consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c616c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Look at rows where the titles dont match\n",
    "movies_df[movies_df['title_wiki'] != movies_df['title_kaggle']][['title_wiki','title_kaggle']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abac04c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confirm there arent any missing titles in the kaggle data\n",
    "# Show any rows where title_kaggle is empty\n",
    "movies_df[(movies_df['title_kaggle'] == '') | (movies_df['title_kaggle'].isnull())]\n",
    "## No results returned, just drop the wikipedia titles column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da417c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare the data between running_time and runtime (use scatter plot)\n",
    "## Scatter polots wont show null values, fill them in with zeros\n",
    "movies_df.fillna(0).plot(x='running_time', y='runtime', kind='scatter')\n",
    "\n",
    "## X axis us wiki and y axis is kaggle, there are more missing entries in the wikipedia data\n",
    "## Keep Kaggle, fill in zeros with wiki data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248c46e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compare budget_wiki and budget_kaggle (scatter plot)\n",
    "movies_df.fillna(0).plot(x='budget_wiki',y='budget_kaggle', kind='scatter')\n",
    "\n",
    "## Keep Kaggle, fill in zeros with wiki data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0e1f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare Box office to revenue (scatter plot)\n",
    "movies_df.fillna(0).plot(x='box_office', y='revenue', kind='scatter')\n",
    "\n",
    "## Might be thrown off by the scale of the large data point, look at evrything less than 1 billion in box_office\n",
    "\n",
    "movies_df.fillna(0)[movies_df['box_office'] < 10**9].plot(x='box_office', y='revenue', kind='scatter')\n",
    "## Keep Kaggle, fill in zeros with wiki data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094e3c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare Release Date Data  Use the regular line plot using only dots\n",
    "## add style=\".\" to plot() method\n",
    "movies_df[['release_date_wiki','release_date_kaggle']].plot(x='release_date_wiki', y='release_date_kaggle', style='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d064728",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Investigate the outlier around 2006\n",
    "movies_df[(movies_df['release_date_wiki'] > '1996-01-01') & (movies_df['release_date_kaggle'] < '1965-01-01')]\n",
    "## Looks like some data merged, just drop the row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0652a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the index\n",
    "movies_df[(movies_df['release_date_wiki'] > '1996-01-01') & (movies_df['release_date_kaggle'] < '1965-01-01')].index\n",
    "## Drop the row\n",
    "movies_df = movies_df.drop(movies_df[(movies_df['release_date_wiki'] > '1996-01-01') & (movies_df['release_date_kaggle'] < '1965-01-01')].index)\n",
    "## Check for null values\n",
    "movies_df[movies_df['release_date_wiki'].isnull()]\n",
    "\n",
    "## Wiki is missing release dates for 11 movies, Kaggle zero, drop wiki data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0ce20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compare the Language datasets (Wikipedia)\n",
    "# movies_df['Language'].value_counts()\n",
    "## Will throw an error becuase some of the language data points are stored as lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06dc105",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conver the lists in language to tuples so that the value_counts() method works (Wikipedia)\n",
    "movies_df['Language'].apply(lambda x: tuple(x) if type(x) == list else x).value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6c7f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Look at the values for Kaggle Language\n",
    "movies_df['original_language'].value_counts()\n",
    "## Keep Kaggle Drop Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3722f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Production Companies\n",
    "movies_df[['Production company(s)','production_companies']]\n",
    "## Drop Wiki Keep Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601fa614",
   "metadata": {},
   "source": [
    "# Put it all Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96056ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop the following , title_wiki, release_date_wiki, Language, and Production company(s) columns.\n",
    "movies_df.drop(columns=['title_wiki','release_date_wiki','Language','Production company(s)'], inplace=True)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6a58c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a function that fills in missing data for a column pair and then drops the redundant column\n",
    "def fill_missing_kaggle_data(df, kaggle_column, wiki_column):\n",
    "    df[kaggle_column] = df.apply(\n",
    "        lambda row: row[wiki_column] if row[kaggle_column] == 0 else row[kaggle_column]\n",
    "        , axis=1)\n",
    "    df.drop(columns=wiki_column, inplace=True)\n",
    "\n",
    "    ## Run the function for the three column pairs that we decided to fill in the zeros\n",
    "\n",
    "    fill_missing_kaggle_data(movies_df, 'runtime', 'running_time')\n",
    "    fill_missing_kaggle_data(movies_df, 'budget_kaggle', 'budget_wiki')\n",
    "    fill_missing_kaggle_data(movies_df, 'revenue', 'box_office')\n",
    "    movies_df\n",
    "\n",
    "    ##  Check for columns with only one value, covert lists to tuples for value_counts() to work\n",
    "    for col in movies_df.columns:\n",
    "        lists_to_tuples = lambda x: tuple(x) if type(x) == list else x\n",
    "        value_counts = movies_df[col].apply(lists_to_tuples).value_counts(dropna=False)\n",
    "        num_values = len(value_counts)\n",
    "        if num_values == 1:\n",
    "            print(col)\n",
    "movies_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becec0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Video has one value (False) drop the column\n",
    "movies_df['video'].value_counts(dropna=False)\n",
    "\n",
    "## Since its false for every row, we dont need to include this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe4ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reorder the columns\n",
    "# Identifying information (IDs, titles, URLs, etc.)\n",
    "# Quantitative facts (runtime, budget, revenue, etc.)\n",
    "# Qualitative facts (genres, languages, country, etc.)\n",
    "# Business data (production companies, distributors, etc.)\n",
    "# People (producers, director, cast, writers, etc.)\n",
    "\n",
    "movies_df = movies_df.loc[:, ['imdb_id','id','title_kaggle','original_title','tagline','belongs_to_collection','url','imdb_link',\n",
    "                       'runtime','budget_kaggle','revenue','release_date_kaggle','popularity','vote_average','vote_count',\n",
    "                       'genres','original_language','overview','spoken_languages','Country',\n",
    "                       'production_companies','production_countries','Distributor',\n",
    "                       'Producer(s)','Director','Starring','Cinematography','Editor(s)','Writer(s)','Composer(s)','Based on'\n",
    "                      ]]\n",
    "\n",
    "## Rename the columns\n",
    "movies_df.rename({'id':'kaggle_id',\n",
    "                  'title_kaggle':'title',\n",
    "                  'url':'wikipedia_url',\n",
    "                  'budget_kaggle':'budget',\n",
    "                  'release_date_kaggle':'release_date',\n",
    "                  'Country':'country',\n",
    "                  'Distributor':'distributor',\n",
    "                  'Producer(s)':'producers',\n",
    "                  'Director':'director',\n",
    "                  'Starring':'starring',\n",
    "                  'Cinematography':'cinematography',\n",
    "                  'Editor(s)':'editors',\n",
    "                  'Writer(s)':'writers',\n",
    "                  'Composer(s)':'composers',\n",
    "                  'Based on':'based_on'\n",
    "                 }, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3366e94b",
   "metadata": {},
   "source": [
    "# Transform and Merge Rating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5351ea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use Groupby on movieID and Rating columns. Take the count for each group.\n",
    "## remane the USERID column to count\n",
    "## pivot data so the movieId =index, the columns will be all the rating values and rows will the counts for each rating value\n",
    "\n",
    "rating_counts = ratings.groupby(['movieId','rating'], as_index=False).count().rename({'userId':'count'}, axis=1).pivot(index='movieId',columns='rating', values='count')\n",
    "                \n",
    "## Rename the columns so they are easier to understand (prepend rating_ to each column with a list comprehension \n",
    "rating_counts.columns = ['rating_' + str(col) for col in rating_counts.columns]\n",
    "\n",
    "## Perform a left merge\n",
    "movies_with_ratings_df = pd.merge(movies_df, rating_counts, left_on='kaggle_id', right_index=True, how='left')\n",
    "\n",
    "## Because not every movie got a rating, fill in missing values with zeros\n",
    "movies_with_ratings_df[rating_counts.columns] = movies_with_ratings_df[rating_counts.columns].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06aca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The connection string for our local server\n",
    "db_string = f\"postgresql://postgres:{db_password}@127.0.0.1:5432/movie_data\"\n",
    "## Create the engine database\n",
    "engine = create_engine(db_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6260a882",
   "metadata": {},
   "source": [
    "# Import the Movie Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2da3684",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To save the movies_df to a SQL table, only specify the name of the stable the engine in the to_sql() method\n",
    "movies_df.to_sql(name='movies', con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cfb2ed",
   "metadata": {},
   "source": [
    "# Import the Ratings Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c1fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not run this yet!\n",
    "for data in pd.read_csv(f'{file_dir}ratings.csv', chunksize=1000000):\n",
    "    data.to_sql(name='ratings', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c381c4a1",
   "metadata": {},
   "source": [
    "# Step 1: Print the number of imported rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f1ff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################## \n",
    "## Print Number of imported Rows (refactoring)\n",
    "## Below is the previous block of code with comments added for refactoring\n",
    "########################################################################################## \n",
    "# create a variable for the number of rows imported\n",
    "# for data in pd.read_csv(f'{file_dir}ratings.csv', chunksize=1000000):\n",
    "\n",
    "    # print out the range of rows that are being imported\n",
    "\n",
    "    # data.to_sql(name='ratings', con=engine, if_exists='append')\n",
    "\n",
    "    # increment the number of rows imported by the chunksize\n",
    "\n",
    "    # print that the rows have finished importing\n",
    "##########################################################################################    \n",
    "# # create a variable for the number of rows imported - call the new variable rows_imported\n",
    "########################################################################################## \n",
    "# rows_imported = 0\n",
    "# for data in pd.read_csv(f'{file_dir}ratings.csv', chunksize=1000000):\n",
    "\n",
    "#     # print out the range of rows that are being imported\n",
    "\n",
    "#     data.to_sql(name='ratings', con=engine, if_exists='append')\n",
    "\n",
    "#     # increment the number of rows imported by the size of 'data'\n",
    "\n",
    "#     # print that the rows have finished importing \n",
    "\n",
    "########################################################################################## \n",
    "# print out the range of rows that are being imported\n",
    "# Setting the end to an empty streing will prevent the output from going to the next line\n",
    "########################################################################################## \n",
    "# create a variable for the number of rows imported\n",
    "# rows_imported = 0\n",
    "# for data in pd.read_csv(f'{file_dir}ratings.csv', chunksize=1000000):\n",
    "\n",
    "#     # print out the range of rows that are being imported\n",
    "#     print(f'importing rows {rows_imported} to {rows_imported + len(data)}...', end='')\n",
    "\n",
    "#     data.to_sql(name='ratings', con=engine, if_exists='append')\n",
    "\n",
    "#     # increment the number of rows imported by the size of 'data'\n",
    "\n",
    "#     # print that the rows have finished importing\n",
    "\n",
    "########################################################################################## \n",
    "############# increment the number of rows impoted by the size of data\n",
    "########################################################################################## \n",
    "# use the compound operator += to add the lendth of the data read in to rows_imported\n",
    "# create a variable for the number of rows imported\n",
    "\n",
    "# rows_imported = 0\n",
    "# for data in pd.read_csv(f'{file_dir}ratings.csv', chunksize=1000000):\n",
    "\n",
    "#     # print out the range of rows that are being imported\n",
    "#     print(f'importing rows {rows_imported} to {rows_imported + len(data)}...', end='')\n",
    "\n",
    "#     data.to_sql(name='ratings', con=engine, if_exists='append')\n",
    "\n",
    "#     # increment the number of rows imported by the size of 'data'\n",
    "#     rows_imported += len(data)\n",
    "\n",
    "#     # print that the rows have finished importing\n",
    "########################################################################################## \n",
    "######################### Print that the rows have finished importing\n",
    "##########################################################################################\n",
    "# # create a variable for the number of rows imported\n",
    "# rows_imported = 0\n",
    "# for data in pd.read_csv(f'{file_dir}ratings.csv', chunksize=1000000):\n",
    "\n",
    "#     # print out the range of rows that are being imported\n",
    "#     print(f'importing rows {rows_imported} to {rows_imported + len(data)}...', end='')\n",
    "\n",
    "#     data.to_sql(name='ratings', con=engine, if_exists='append')\n",
    "\n",
    "#     # increment the number of rows imported by the size of 'data'\n",
    "#     rows_imported += len(data)\n",
    "\n",
    "#     # print that the rows have finished importing\n",
    "#     print('Done.')\n",
    "##########################################################################################    \n",
    "# ###### Done Refactoring Delete Comments\n",
    "# rows_imported = 0\n",
    "# for data in pd.read_csv(f'{file_dir}ratings.csv', chunksize=1000000):\n",
    "\n",
    "#     print(f'importing rows {rows_imported} to {rows_imported + len(data)}...', end='')\n",
    "#     data.to_sql(name='ratings', con=engine, if_exists='append')\n",
    "#     rows_imported += len(data)\n",
    "\n",
    "#     print(f'Done.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eb572d",
   "metadata": {},
   "source": [
    "# Step 2: Print Elapsed Time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a833da",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################\n",
    "##  Add 2 new comments, one before the for loop and one inside the for loop, right before the last final print()\n",
    "#  The first comment is to get the start time from time.time()\n",
    "# The second comment is to add the elapsed time to the final printout\n",
    "####################################################################################################################\n",
    "# rows_imported = 0\n",
    "# # get the start_time from time.time()\n",
    "# for data in pd.read_csv(f'{file_dir}ratings.csv', chunksize=1000000):\n",
    "\n",
    "#     print(f'importing rows {rows_imported} to {rows_imported + len(data)}...', end='')\n",
    "#     data.to_sql(name='ratings', con=engine, if_exists='append')\n",
    "#     rows_imported += len(data)\n",
    "\n",
    "#     # add elapsed time to final print out\n",
    "#     print(f'Done.')\n",
    "\n",
    "\n",
    "####################################################################################################################\n",
    "## Get the start_time from time.time()\n",
    "####################################################################################################################\n",
    "## The start_time = time.time() method will intitalize the start_time with the current time\n",
    "\n",
    "# rows_imported = 0\n",
    "# # get the start_time from time.time()\n",
    "# start_time = time.time()\n",
    "# for data in pd.read_csv(f'{file_dir}ratings.csv', chunksize=1000000):\n",
    "#     print(f'importing rows {rows_imported} to {rows_imported + len(data)}...', end='')\n",
    "#     data.to_sql(name='ratings', con=engine, if_exists='append')\n",
    "#     rows_imported += len(data)\n",
    "\n",
    "#     # add elapsed time to final print out\n",
    "#     print(f'Done.')\n",
    "\n",
    "######################################################################################################################\n",
    "## The elapsed time is simply time.time() - start_time, which can be added directly into an f string\n",
    "## Will take some time to load\n",
    "\n",
    "rows_imported = 0\n",
    "# get the start_time from time.time()\n",
    "start_time = time.time()\n",
    "for data in pd.read_csv(f'{file_dir}ratings.csv', chunksize=1000000):\n",
    "    print(f'importing rows {rows_imported} to {rows_imported + len(data)}...', end='')\n",
    "    data.to_sql(name='ratings', con=engine, if_exists='append')\n",
    "    rows_imported += len(data)\n",
    "\n",
    "    # add elapsed time to final print out\n",
    "    print(f'Done. {time.time() - start_time} total seconds elapsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26e658c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
